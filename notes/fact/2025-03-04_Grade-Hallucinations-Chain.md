---
date: 2025-03-04
type: fact
aliases:
  -
hubs:
  - "[[langgraph]]"
---

# Grade Hallucinations Chain

In this topic, we need to create a chain to check if the answers generated by LLM are based on hallucinations rather than documents. Then we need to write tests to verify if this chain is functioning correctly.

```sh
 tree
.
├── graph
│   ├── chains
│   │   ├── generation.py
│   │   ├── hallucination_grader.py # new file, to create a chain to grade the LLM answer
│   │   ├── __init__.py
│   │   ├── retrieval_grader.py
│   │   └── tests
│   │       ├── __init__.py
│   │       └── test_chains.py
│   ├── consts.py
│   ├── graph.py
│   ├── __init__.py
│   ├── nodes
│   │   ├── generate.py
│   │   ├── grade_documents.py
│   │   ├── __init__.py
│   │   ├── retrieve.py
│   │   └── web_search.py
│   └── state.py
├── ingestion.py
├── main.py
├── Pipfile
└── Pipfile.lock
```

```py
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI


llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Create a Pydantic model to structure the output of the LLM
class GradeHallucinations(BaseModel):
    """Binary score for hallucination present in generation answer."""

    binary_score: bool = Field(
        description="Answer is grounded in the facts, True or False."
    )


# use .with_structured_output to wrap the LLM with the Pydantic model above
# it'll force the LLM to do function calling to the the Pydantic model as tool under the hood
structured_llm_grader = llm.with_structured_output(GradeHallucinations)


hallucination_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """You are a grader assessing whether an LLM generation is grounded in / supperted by a set of retrieved facts. \nGive a binary score True or False. True means that the answer is grounded in / supported by the set of facts."""
            ),
        ("human", "Set of facts: \n\n {documents} \n\n LLM generation: {generation}")
    ]
)


# Compose above components to a chain that to check if the answers are based on the facts we retrieved
hallucination_grader = hallucination_prompt | structured_llm_grader

```

Then, we write tests to verify if this chain is functioning correctly.

```py
from dotenv import load_dotenv
load_dotenv()
from graph.chains.retrieval_grader import GradeDocument, retrieval_grader
from ingestion import retriever
from graph.chains.generation import generation_chain 
from graph.chains.hallucination_grader import hallucination_grader, GradeHallucinations # import


def test_retrival_grader_answer_yes() -> None: ...

def test_retrival_grader_answer_no() -> None: ...

def test_generation_chain() -> None: ...

# Test the hallucination grader with below two tests
def test_hallucination_grader_true() -> None:
    question = "agent memory"
    docs = retriever.invoke(question)
    generation = generation_chain.invoke({"context": docs, "question": question})
    res = hallucination_grader.invoke(
        {
            "documents": docs,
            "generation": generation
        }
    )

    if isinstance(res, GradeHallucinations):
        assert res.binary_score
    else:
        assert False

def test_hallucination_grader_false() -> None:
    question = "agent memory"
    docs = retriever.invoke(question)
    res = hallucination_grader.invoke(
        {
            "documents": docs,
            "generation": "this is how to make a cake" # give a NO-relation answer here to test the False case
        }
    )

    if isinstance(res, GradeHallucinations):
        assert not res.binary_score
        #      ^^^
    else:
        assert False

```

Run the tests:

```sh
 pytest . -s -v
=============================== test session starts ===============================
platform linux -- Python 3.13.1, pytest-8.3.4, pluggy-1.5.0 -- /home/matt/.local/sh
are/virtualenvs/langgraph-course-uhZ6dcGU/bin/python
cachedir: .pytest_cache
rootdir: /home/matt/Projects/langgraph-course
plugins: langsmith-0.3.11, anyio-4.8.0
collected 2 items                                                                                                                                                                               

graph/chains/tests/test_chains.py::test_hallucination_grader_true PASSED
graph/chains/tests/test_chains.py::test_hallucination_grader_false PASSED

```
